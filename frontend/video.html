<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>PitchLense - Video Follow-up</title>
  <link rel="icon" type="image/svg+xml" href="/static/logo.svg" />
  <meta name="description" content="Record your follow-up video response for PitchLense" />
  
  <!-- Tailwind Play CDN with custom theme -->
  <script>
    tailwind.config = {
      theme: {
        extend: {
          colors: {
            background: '#1E1E21',
            surface: '#2E3137',
            muted: '#2E3137',
            text: '#ffffff',
            secondary: '#cfd4dd',
            accent: '#f1d85b',
            accent2: '#78e6d0'
          },
          fontFamily: {
            sans: ['Inter', 'system-ui', 'Segoe UI', 'Roboto', 'Helvetica', 'Arial', 'sans-serif']
          },
          boxShadow: {
            card: '0 10px 30px rgba(0,0,0,0.35)'
          }
        }
      }
    };
  </script>
  <script src="https://cdn.tailwindcss.com"></script>
  
  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&display=swap" rel="stylesheet">
  
  <!-- Base styles -->
  <link rel="stylesheet" href="./styles.css" />
  
  <!-- SweetAlert2 -->
  <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11"></script>
  
  <!-- Gemini Live API -->
  <script type="module">
    import { GoogleGenAI, Modality } from 'https://unpkg.com/@google/genai@latest/dist/index.esm.js';
    
    // Make it globally available
    window.GoogleGenAI = GoogleGenAI;
    window.Modality = Modality;
  </script>
</head>
<body class="bg-background text-text font-sans antialiased selection:bg-accent selection:text-white h-screen overflow-hidden">
  <div class="h-screen flex flex-col">
    <!-- Header -->
    <header class="bg-surface border-b border-white/10 px-6 py-4 flex-shrink-0">
      <div class="flex items-center justify-between">
        <div class="flex items-center gap-3">
          <img src="/static/logo.svg" class="w-8 h-8" alt="PitchLense">
          <h1 class="text-xl font-bold text-white">PitchLense Video Follow-up</h1>
        </div>
        <div class="text-sm">
          <a href="#" class="text-white/60 hover:text-accent transition-colors" title="Drop email to connectamanulla@gmail.com">
            Facing issue?
          </a>
        </div>
      </div>
    </header>

    <!-- Main Content -->
    <main class="flex-1 flex min-h-0">
      <!-- Video Section (50%) -->
      <div class="w-1/2 p-6 min-w-0">
        <div class="h-full flex flex-col">
          <!-- Video Container -->
          <div class="flex-1 bg-surface border border-white/10 rounded-lg p-6 min-h-0">
            <div class="h-full flex flex-col">
              <!-- Video Preview -->
              <div class="flex-1 bg-black rounded-lg mb-4 flex items-center justify-center relative overflow-hidden">
                <video id="videoPreview" autoplay muted class="w-full h-full object-contain hidden"></video>
                <div id="videoPlaceholder" class="text-center text-white/60">
                  <svg class="w-16 h-16 mx-auto mb-4 text-white/40" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 10l4.553-2.276A1 1 0 0121 8.618v6.764a1 1 0 01-1.447.894L15 14M5 18h8a2 2 0 002-2V8a2 2 0 00-2-2H5a2 2 0 00-2 2v8a2 2 0 002 2z"></path>
                  </svg>
                  <p class="text-lg">Camera Preview</p>
                  <p class="text-sm">Select a camera to start</p>
                </div>
                
                <!-- Audio Level Indicator -->
                <div id="audioLevelIndicator" class="absolute bottom-4 left-4 hidden">
                  <div class="bg-black/70 rounded-lg p-2">
                    <div class="flex items-center gap-2">
                      <svg class="w-4 h-4 text-white" fill="currentColor" viewBox="0 0 24 24">
                        <path d="M3 9v6h4l5 5V4L7 9H3zm13.5 3c0-1.77-1.02-3.29-2.5-4.03v8.05c1.48-.73 2.5-2.25 2.5-4.02zM14 3.23v2.06c2.89.86 5 3.54 5 6.71s-2.11 5.85-5 6.71v2.06c4.01-.91 7-4.49 7-8.77s-2.99-7.86-7-8.77z"/>
                      </svg>
                      <div class="flex items-center gap-1">
                        <div id="audioBar1" class="w-1 h-2 bg-green-400 rounded"></div>
                        <div id="audioBar2" class="w-1 h-3 bg-green-400 rounded"></div>
                        <div id="audioBar3" class="w-1 h-4 bg-green-400 rounded"></div>
                        <div id="audioBar4" class="w-1 h-5 bg-green-400 rounded"></div>
                        <div id="audioBar5" class="w-1 h-6 bg-green-400 rounded"></div>
                      </div>
                    </div>
                  </div>
                </div>
              </div>

              <!-- Device Selection -->
              <div class="space-y-4">
                <!-- Device Selection Row -->
                <div class="grid grid-cols-2 gap-4">
                  <!-- Camera Selection -->
                  <div class="flex flex-col gap-2">
                    <label class="text-white font-medium text-sm">Camera:</label>
                    <select id="cameraSelect" class="bg-[#1E1E21] border border-white/20 rounded-lg px-3 py-2 text-white focus:outline-none focus:border-accent">
                      <option value="">Select Camera...</option>
                    </select>
                  </div>

                  <!-- Audio Selection -->
                  <div class="flex flex-col gap-2">
                    <label class="text-white font-medium text-sm">Audio:</label>
                    <select id="audioSelect" class="bg-[#1E1E21] border border-white/20 rounded-lg px-3 py-2 text-white focus:outline-none focus:border-accent">
                      <option value="">Select Audio Device...</option>
                    </select>
                  </div>
                </div>

                <!-- Status indicators moved to dock -->

                <!-- Completion Message -->
                <div id="completionMessage" class="hidden">
                  <div class="bg-green-900/20 border border-green-500/30 rounded-lg p-6 text-center">
                    <div class="w-16 h-16 bg-green-500 rounded-full flex items-center justify-center mx-auto mb-4">
                      <svg class="w-8 h-8 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path>
                      </svg>
                    </div>
                    <h3 class="text-xl font-semibold text-white mb-2">Video Submitted Successfully!</h3>
                    <p class="text-white/70 mb-4">Your video has been processed and analyzed. The transcript and answers have been saved.</p>
                    <div class="space-y-3">
                      <p class="text-white/60 text-sm">You can now safely close this tab:</p>
                      <div class="flex flex-col sm:flex-row gap-2 justify-center">
                        <button onclick="closeTab()" class="px-6 py-2 bg-green-600 text-white rounded-lg hover:bg-green-700 transition-colors font-medium">
                          Try Auto Close
                        </button>
                        <button onclick="showCloseInstructions()" class="px-6 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition-colors font-medium">
                          Manual Close Instructions
                        </button>
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

      <!-- Questions Section (50%) -->
      <div class="w-1/2 bg-surface border-l border-white/10 p-6 flex flex-col min-h-0">
        <h2 class="text-lg font-semibold text-white mb-4 flex-shrink-0">Follow-up Questions</h2>
        <div id="questionsContainer" class="space-y-3 overflow-y-auto flex-1 min-h-0">
          <!-- Questions will be loaded here -->
        </div>
      </div>
    </main>


    <!-- Bottom Dock -->
    <div id="bottomDock" class="fixed bottom-6 left-1/2 transform -translate-x-1/2">
      <div class="bg-surface/95 backdrop-blur-sm border border-white/20 rounded-full px-6 py-3 flex items-center gap-4 shadow-lg">
        <!-- Voice Visualization (shown during introduction) -->
        <div id="voiceVisualizationDock" class="flex items-center gap-3 px-4 py-2 bg-gradient-to-r from-blue-900/30 to-purple-900/30 border border-blue-500/30 rounded-full hidden">
          <!-- 3D Sphere Animation -->
          <div class="relative w-8 h-8">
            <!-- Outer pulsing sphere -->
            <div class="absolute inset-0 rounded-full bg-gradient-to-r from-blue-400 to-purple-500 animate-pulse opacity-30"></div>
            <!-- Middle sphere -->
            <div class="absolute inset-1 rounded-full bg-gradient-to-r from-blue-500 to-purple-600 animate-ping opacity-50"></div>
            <!-- Inner sphere -->
            <div class="absolute inset-2 rounded-full bg-gradient-to-r from-blue-600 to-purple-700 animate-bounce"></div>
            <!-- Speech waveform animation -->
            <div class="absolute inset-0 flex items-center justify-center">
              <div class="flex items-center gap-0.5">
                <div class="w-0.5 h-3 bg-white/60 rounded-full animate-pulse"></div>
                <div class="w-0.5 h-4 bg-white/80 rounded-full animate-pulse" style="animation-delay: 0.1s"></div>
                <div class="w-0.5 h-2 bg-white/60 rounded-full animate-pulse" style="animation-delay: 0.2s"></div>
                <div class="w-0.5 h-3 bg-white/80 rounded-full animate-pulse" style="animation-delay: 0.3s"></div>
                <div class="w-0.5 h-2 bg-white/60 rounded-full animate-pulse" style="animation-delay: 0.4s"></div>
              </div>
            </div>
          </div>
          <span class="text-white text-sm font-medium">AI Introduction</span>
        </div>
        
        <!-- Start Recording Button -->
        <button id="startRecording" class="p-3 bg-red-600 text-white rounded-full hover:bg-red-700 transition-colors group disabled:opacity-50 disabled:cursor-not-allowed" title="Start Recording" disabled>
          <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24">
            <circle cx="12" cy="12" r="10"/>
          </svg>
        </button>
        
        <!-- Stop Recording Button -->
        <button id="stopRecording" class="p-3 bg-gray-600 text-white rounded-full hover:bg-gray-700 transition-colors group hidden" title="Stop Recording">
          <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24">
            <rect x="6" y="6" width="12" height="12" rx="2"/>
          </svg>
        </button>
        
        <!-- Recording Timer (shown during recording) -->
        <div id="recordingTimer" class="flex items-center gap-2 px-4 py-2 bg-red-900/30 border border-red-500/30 rounded-full hidden">
          <div class="w-2 h-2 bg-red-500 rounded-full animate-pulse"></div>
          <span id="recordingTime" class="text-white text-sm font-medium">00:00</span>
        </div>
        
        <!-- Upload Progress (shown during upload) -->
        <div id="uploadProgressDock" class="flex items-center gap-3 px-4 py-2 bg-blue-900/30 border border-blue-500/30 rounded-full hidden">
          <div class="w-4 h-4 border-2 border-blue-400 border-t-transparent rounded-full animate-spin"></div>
          <div class="flex flex-col">
            <span class="text-white text-xs font-medium">Uploading...</span>
            <div class="w-20 bg-white/20 rounded-full h-1">
              <div id="uploadBarDock" class="bg-blue-400 h-1 rounded-full transition-all duration-300" style="width: 0%"></div>
            </div>
          </div>
        </div>
        
        <!-- Processing Loader (shown during processing) -->
        <div id="processingLoaderDock" class="flex items-center gap-3 px-4 py-2 bg-yellow-900/30 border border-yellow-500/30 rounded-full hidden">
          <div class="w-4 h-4 border-2 border-yellow-400 border-t-transparent rounded-full animate-spin"></div>
          <span class="text-white text-xs font-medium">Processing...</span>
        </div>
        
        <!-- Replay Video Button -->
        <button id="replayVideo" class="p-3 bg-blue-600 text-white rounded-full hover:bg-blue-700 transition-colors group hidden" title="Replay Video">
          <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24">
            <path d="M8 5v14l11-7z"/>
          </svg>
        </button>
        
        <!-- Reshoot Video Button -->
        <button id="reshootVideo" class="p-3 bg-orange-600 text-white rounded-full hover:bg-orange-700 transition-colors group hidden" title="Reshoot Video">
          <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 4v5h.582m15.356 2A8.001 8.001 0 004.582 9m0 0H9m11 11v-5h-.581m0 0a8.003 8.003 0 01-15.357-2m15.357 2H15"></path>
          </svg>
        </button>
        
        <!-- Submit Video Button -->
        <button id="submitFinalVideo" class="p-3 bg-green-600 text-white rounded-full hover:bg-green-700 transition-colors group hidden" title="Submit Video">
          <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 19l9 2-9-18-9 18 9-2zm0 0v-8"></path>
          </svg>
        </button>
      </div>
    </div>
  </div>

  <!-- Welcome Popup -->
  <div id="welcomePopup" class="fixed inset-0 bg-black/50 flex items-center justify-center z-50">
    <div class="bg-[#2E3137] border border-white/10 rounded-lg p-6 max-w-2xl mx-4 shadow-lg">
      <div class="text-center">
        <div class="w-16 h-16 rounded-full flex items-center justify-center mx-auto mb-4" style="background-color: #f1d85b;">
          <svg class="w-8 h-8 text-black" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 10l4.553-2.276A1 1 0 0121 8.618v6.764a1 1 0 01-1.447.894L15 14M5 18h8a2 2 0 002-2V8a2 2 0 00-2-2H5a2 2 0 00-2 2v8a2 2 0 002 2z"></path>
          </svg>
        </div>
        <h2 class="text-2xl font-bold text-white mb-4">Welcome to PitchLense Video Follow-up</h2>
        <div class="text-left text-white/80 space-y-4 mb-6">
          <p><strong>📹 Video Recording:</strong> Use the left side to record your video response</p>
          <p><strong>❓ Questions:</strong> Review the follow-up questions on the right side</p>
          <p><strong>🎯 Instructions:</strong></p>
          <ol class="list-decimal list-inside space-y-2 ml-4">
            <li>Select your camera from the dropdown</li>
            <li>Select your audio device from the dropdown</li>
            <li>Review all questions on the right</li>
            <li>Click "Start Recording" when ready</li>
            <li>Answer each question clearly and accurately</li>
            <li>Click "Stop Recording" when finished</li>
            <li>Click "Submit Video" to upload and process</li>
          </ol>
          <p class="text-accent font-medium">💡 Tip: Speak clearly and ensure good lighting for best results!</p>
        </div>
        <button onclick="closeWelcomePopup()" class="px-6 py-2 text-black rounded-lg transition-colors font-medium" style="background-color: #f1d85b;" onmouseover="this.style.backgroundColor='#e6c547'" onmouseout="this.style.backgroundColor='#f1d85b'">
          Got it, let's start!
        </button>
      </div>
    </div>
  </div>

  <script>
    // Global variables
    let mediaRecorder;
    let recordedChunks = [];
    let recordingStartTime;
    let recordingTimerInterval;
    let stream;
    let audioContext;
    let analyser;
    let microphone;
    let animationFrame;

    // DOM elements
    const videoPreview = document.getElementById('videoPreview');
    const videoPlaceholder = document.getElementById('videoPlaceholder');
    const cameraSelect = document.getElementById('cameraSelect');
    const audioSelect = document.getElementById('audioSelect');
    const startRecording = document.getElementById('startRecording');
    const stopRecording = document.getElementById('stopRecording');
    const recordingTime = document.getElementById('recordingTime');
    const recordingTimer = document.getElementById('recordingTimer');
    const uploadProgressDock = document.getElementById('uploadProgressDock');
    const uploadBarDock = document.getElementById('uploadBarDock');
    const processingLoaderDock = document.getElementById('processingLoaderDock');
    const completionMessage = document.getElementById('completionMessage');
    const questionsContainer = document.getElementById('questionsContainer');
    const voiceVisualizationDock = document.getElementById('voiceVisualizationDock');

    // Get follow-up ID from URL
    const urlParams = new URLSearchParams(window.location.search);
    const followupId = urlParams.get('id');

    if (!followupId) {
      alert('Invalid follow-up ID');
      window.location.href = '/';
    }

    // Initialize page
    async function initialize() {
      await loadQuestions();
      await setupCamera();
      await showIntroduction();
    }

    // Load questions from follow-up query
    async function loadQuestions() {
      try {
        const response = await fetch(`/api/follow-up-queries/${followupId}`, {
          credentials: 'include'
        });

        if (!response.ok) {
          throw new Error('Failed to load questions');
        }

        const data = await response.json();
        const questions = data.questions || [];

        questionsContainer.innerHTML = questions.map((question, index) => `
          <div class="bg-[#1E1E21] border border-white/10 rounded-lg p-2">
            <div class="flex items-start gap-2">
              <span class="bg-accent text-[#1E1E21] text-xs font-bold px-1.5 py-0.5 rounded-full flex-shrink-0">${index + 1}</span>
              <p class="text-white text-xs leading-relaxed">${question}</p>
            </div>
          </div>
        `).join('');
        
        // Store questions globally for introduction
        window.questions = questions;
      } catch (error) {
        console.error('Error loading questions:', error);
        questionsContainer.innerHTML = '<p class="text-white/60">Failed to load questions</p>';
        window.questions = [];
      }
    }

    // Show AI introduction
    async function showIntroduction() {
      try {
        // Show voice visualization in dock
        voiceVisualizationDock.classList.remove('hidden');
        
        // Generate introduction text
        const introductionPrompt = await generateIntroductionText();
        
        // Generate and play audio introduction
        await playIntroductionAudio(introductionPrompt);
        
        // Hide dock visualization and show start recording button
        voiceVisualizationDock.classList.add('hidden');
        startRecording.disabled = false;
        
      } catch (error) {
        console.error('Error showing introduction:', error);
        // Fallback: hide visualization and enable recording
        voiceVisualizationDock.classList.add('hidden');
        startRecording.disabled = false;
      }
    }

    // Generate introduction text using Gemini
    async function generateIntroductionText() {
      const questions = window.questions || [];
      const questionsText = questions.join(', ');
      
      const prompt = `Create a brief, friendly introduction (under 50 words) for a video interview session. 
      
      Context: The user will be answering questions about: ${questionsText}
      
      Instructions:
      - Welcome them warmly
      - Explain this is a video interview
      - Briefly mention what topics will be covered
      - Give simple instructions (speak clearly, take your time)
      - Keep it conversational and encouraging
      - End with "When you're ready, click the record button to begin"
      
      Make it sound natural and professional.`;

      try {
        // Try to use Gemini Live API if available
        if (window.GoogleGenAI && window.Modality) {
          return await generateWithGemini(prompt);
        } else {
          // Fallback to a generic introduction
          return generateFallbackIntroduction(questions);
        }
      } catch (error) {
        console.error('Error generating introduction:', error);
        return generateFallbackIntroduction(questions);
      }
    }

    // Generate introduction with Gemini Live API
    async function generateWithGemini(prompt) {
      try {
        const ai = new window.GoogleGenAI({ 
          apiKey: 'YOUR_GEMINI_API_KEY' // Replace with actual API key
        });
        
        const model = ai.getGenerativeModel({ model: "gemini-2.0-flash-exp" });
        const result = await model.generateContent(prompt);
        const response = await result.response;
        return response.text();
      } catch (error) {
        console.error('Gemini API error:', error);
        throw error;
      }
    }

    // Generate fallback introduction
    function generateFallbackIntroduction(questions) {
      const topics = questions.slice(0, 3).join(', ');
      return `Welcome to your video interview! I'm excited to learn about your experience and insights. Today we'll be discussing ${topics} and other related topics. Please speak clearly and take your time with your responses. This is your opportunity to share your thoughts and experiences in detail. When you're ready, click the record button to begin.`;
    }

    // Play introduction audio
    async function playIntroductionAudio(text) {
      try {
        // Use Web Speech API for audio
        if ('speechSynthesis' in window) {
          const utterance = new SpeechSynthesisUtterance(text);
          
          // Enhanced voice settings for more human-like speech
          utterance.rate = 0.85;        // Slightly slower for natural pace
          utterance.pitch = 1.1;        // Slightly higher pitch for warmth
          utterance.volume = 0.9;        // Higher volume for clarity
          
          // Wait for voices to load if needed
          let voices = speechSynthesis.getVoices();
          if (voices.length === 0) {
            await new Promise(resolve => {
              speechSynthesis.onvoiceschanged = resolve;
            });
            voices = speechSynthesis.getVoices();
          }
          
          // Enhanced voice selection for more human-like quality
          const preferredVoices = [
            // Ursa voice (primary choice)
            'Ursa',
            // Premium voices (best quality)
            'Samantha', 'Karen', 'Victoria', 'Alex', 'Daniel',
            // Google voices
            'Google UK English Female', 'Google UK English Male',
            'Google US English Female', 'Google US English Male',
            // Microsoft voices
            'Microsoft Zira Desktop', 'Microsoft David Desktop',
            'Microsoft Susan Desktop', 'Microsoft Mark Desktop',
            // Amazon voices
            'Amazon Polly Joanna', 'Amazon Polly Matthew',
            'Amazon Polly Amy', 'Amazon Polly Brian',
            // Other high-quality voices
            'Karen', 'Moira', 'Tessa', 'Veena', 'Rishi'
          ];
          
          // Find the best available voice
          let selectedVoice = null;
          
          // First, try to find exact matches
          for (const preferredName of preferredVoices) {
            selectedVoice = voices.find(voice => 
              voice.name === preferredName || 
              voice.name.includes(preferredName)
            );
            if (selectedVoice) break;
          }
          
          // If no exact match, find the best quality English voice
          if (!selectedVoice) {
            selectedVoice = voices.find(voice => 
              voice.lang.startsWith('en') && 
              (voice.name.includes('Female') || 
               voice.name.includes('Samantha') ||
               voice.name.includes('Karen') ||
               voice.name.includes('Victoria') ||
               voice.name.includes('Google') ||
               voice.name.includes('Microsoft') ||
               voice.name.includes('Amazon'))
            );
          }
          
          // Fallback to any English voice
          if (!selectedVoice) {
            selectedVoice = voices.find(voice => voice.lang.startsWith('en'));
          }
          
          if (selectedVoice) {
            utterance.voice = selectedVoice;
            console.log('Using voice:', selectedVoice.name);
          }
          
          // Enhanced speech settings
          utterance.rate = 0.85;  // Natural speaking pace
          utterance.pitch = 1.1;  // Slightly higher for warmth
          utterance.volume = 0.9; // Clear volume
          
          return new Promise((resolve) => {
            utterance.onend = resolve;
            utterance.onerror = resolve;
            speechSynthesis.speak(utterance);
          });
        } else {
          // Fallback: just wait a bit
          return new Promise(resolve => setTimeout(resolve, 3000));
        }
      } catch (error) {
        console.error('Error playing introduction audio:', error);
        // Fallback: just wait a bit
        return new Promise(resolve => setTimeout(resolve, 3000));
      }
    }

    // Setup camera and audio devices
    async function setupCamera() {
      try {
        // Request permissions first to get proper device labels
        await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
        
        const devices = await navigator.mediaDevices.enumerateDevices();
        const videoDevices = devices.filter(device => device.kind === 'videoinput');
        const audioDevices = devices.filter(device => device.kind === 'audioinput');

        console.log('Available video devices:', videoDevices);
        console.log('Available audio devices:', audioDevices);

        // Setup camera dropdown
        cameraSelect.innerHTML = '<option value="">Select Camera...</option>';
        videoDevices.forEach((device, index) => {
          const option = document.createElement('option');
          option.value = device.deviceId;
          // Use device label or create a more descriptive name
          const deviceName = device.label || `Camera ${index + 1}`;
          option.textContent = deviceName;
          cameraSelect.appendChild(option);
        });

        // Setup audio dropdown
        audioSelect.innerHTML = '<option value="">Select Audio Device...</option>';
        audioDevices.forEach((device, index) => {
          const option = document.createElement('option');
          option.value = device.deviceId;
          // Use device label or create a more descriptive name
          const deviceName = device.label || `Audio Device ${index + 1}`;
          option.textContent = deviceName;
          audioSelect.appendChild(option);
        });

        // Auto-select first devices if available
        if (videoDevices.length > 0) {
          cameraSelect.value = videoDevices[0].deviceId;
        }
        if (audioDevices.length > 0) {
          audioSelect.value = audioDevices[0].deviceId;
        }

        // Start camera if we have a video device selected
        if (videoDevices.length > 0) {
          await startCamera();
        }

        cameraSelect.addEventListener('change', startCamera);
        audioSelect.addEventListener('change', startCamera);
      } catch (error) {
        console.error('Error setting up devices:', error);
        // Fallback: try without permissions
        try {
          const devices = await navigator.mediaDevices.enumerateDevices();
          const videoDevices = devices.filter(device => device.kind === 'videoinput');
          const audioDevices = devices.filter(device => device.kind === 'audioinput');

          // Setup camera dropdown
          cameraSelect.innerHTML = '<option value="">Select Camera...</option>';
          videoDevices.forEach((device, index) => {
            const option = document.createElement('option');
            option.value = device.deviceId;
            option.textContent = device.label || `Camera ${index + 1}`;
            cameraSelect.appendChild(option);
          });

          // Setup audio dropdown
          audioSelect.innerHTML = '<option value="">Select Audio Device...</option>';
          audioDevices.forEach((device, index) => {
            const option = document.createElement('option');
            option.value = device.deviceId;
            option.textContent = device.label || `Audio Device ${index + 1}`;
            audioSelect.appendChild(option);
          });

          if (videoDevices.length > 0) {
            cameraSelect.value = videoDevices[0].deviceId;
          }
          if (audioDevices.length > 0) {
            audioSelect.value = audioDevices[0].deviceId;
          }

          cameraSelect.addEventListener('change', startCamera);
          audioSelect.addEventListener('change', startCamera);
        } catch (fallbackError) {
          console.error('Fallback device setup failed:', fallbackError);
        }
      }
    }

    // Start camera
    async function startCamera() {
      const videoDeviceId = cameraSelect.value;
      const audioDeviceId = audioSelect.value;
      
      if (!videoDeviceId) return;

      try {
        // Stop existing stream
        if (stream) {
          stream.getTracks().forEach(track => track.stop());
        }

        // Prepare constraints
        const constraints = {
          video: {
            deviceId: { exact: videoDeviceId },
            width: { ideal: 1280 },
            height: { ideal: 720 },
            facingMode: 'user'
          }
        };

        // Add audio constraints if audio device is selected
        if (audioDeviceId) {
          constraints.audio = {
            deviceId: { exact: audioDeviceId }
          };
        } else {
          constraints.audio = true; // Use default audio device
        }

        // Start new stream with selected devices
        stream = await navigator.mediaDevices.getUserMedia(constraints);

        videoPreview.srcObject = stream;
        videoPreview.classList.remove('hidden');
        videoPlaceholder.classList.add('hidden');
        // Start recording button will be enabled after introduction
        // startRecording.disabled = false;
        
        // Setup audio level monitoring
        setupAudioLevelMonitoring(stream);
      } catch (error) {
        console.error('Error starting camera:', error);
        Swal.fire({
          icon: 'error',
          title: 'Camera Access Failed',
          text: 'Failed to access camera. Please check permissions.',
          confirmButtonColor: '#f1d85b',
          confirmButtonText: 'OK'
        });
      }
    }

    // Start recording
    function startRecordingVideo() {
      if (!stream) return;

      recordedChunks = [];
      mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'video/webm;codecs=vp9,opus'
      });

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          recordedChunks.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        const blob = new Blob(recordedChunks, { type: 'video/webm' });
        const url = URL.createObjectURL(blob);
        recordedVideoBlob = blob;
        
        // Update video preview to show recorded video (but don't auto-play)
        videoPreview.src = url;
        videoPreview.srcObject = null;
        videoPreview.muted = false; // Unmute for playback
        
        // Ensure the video element is visible
        videoPreview.classList.remove('hidden');
        
        // Show post-recording controls in dock
        showPostRecordingControls();
      };

      mediaRecorder.start();
      recordingStartTime = Date.now();
      startRecordingTimer();
      
      // Update dock controls
      startRecording.classList.add('hidden');
      stopRecording.classList.remove('hidden');
      recordingTimer.classList.remove('hidden');
    }

    // Stop recording
    function stopRecordingVideo() {
      if (mediaRecorder && mediaRecorder.state === 'recording') {
        mediaRecorder.stop();
        clearInterval(recordingTimerInterval);
        
        // Update dock controls
        stopRecording.classList.add('hidden');
        recordingTimer.classList.add('hidden');
      }
    }

    // Show post-recording controls in dock
    function showPostRecordingControls() {
      // Hide start recording button
      startRecording.classList.add('hidden');
      // Show replay, reshoot, and submit buttons
      document.getElementById('replayVideo').classList.remove('hidden');
      document.getElementById('reshootVideo').classList.remove('hidden');
      document.getElementById('submitFinalVideo').classList.remove('hidden');
    }

    // Hide post-recording controls
    function hidePostRecordingControls() {
      document.getElementById('replayVideo').classList.add('hidden');
      document.getElementById('reshootVideo').classList.add('hidden');
      document.getElementById('submitFinalVideo').classList.add('hidden');
    }

    // Simulate upload progress
    function simulateUploadProgress() {
      let progress = 0;
      const interval = setInterval(() => {
        progress += Math.random() * 15; // Random increment
        if (progress > 90) progress = 90; // Cap at 90% until actual completion
        
        uploadBarDock.style.width = progress + '%';
        
        if (progress >= 90) {
          clearInterval(interval);
        }
      }, 200);
    }

    // Start recording timer
    function startRecordingTimer() {
      recordingTimerInterval = setInterval(() => {
        const elapsed = Date.now() - recordingStartTime;
        const minutes = Math.floor(elapsed / 60000);
        const seconds = Math.floor((elapsed % 60000) / 1000);
        recordingTime.textContent = `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
      }, 1000);
    }

    // Setup audio level monitoring
    function setupAudioLevelMonitoring(stream) {
      try {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        analyser = audioContext.createAnalyser();
        microphone = audioContext.createMediaStreamSource(stream);
        
        analyser.fftSize = 256;
        microphone.connect(analyser);
        
        const audioLevelIndicator = document.getElementById('audioLevelIndicator');
        audioLevelIndicator.classList.remove('hidden');
        
        const dataArray = new Uint8Array(analyser.frequencyBinCount);
        
        function updateAudioLevel() {
          analyser.getByteFrequencyData(dataArray);
          
          // Calculate average volume
          let sum = 0;
          for (let i = 0; i < dataArray.length; i++) {
            sum += dataArray[i];
          }
          const average = sum / dataArray.length;
          const normalizedLevel = average / 255;
          
          // Update visual bars
          const bars = ['audioBar1', 'audioBar2', 'audioBar3', 'audioBar4', 'audioBar5'];
          bars.forEach((barId, index) => {
            const bar = document.getElementById(barId);
            const threshold = (index + 1) / 5;
            if (normalizedLevel >= threshold) {
              bar.style.backgroundColor = normalizedLevel > 0.8 ? '#ef4444' : '#10b981';
            } else {
              bar.style.backgroundColor = '#374151';
            }
          });
          
          animationFrame = requestAnimationFrame(updateAudioLevel);
        }
        
        updateAudioLevel();
      } catch (error) {
        console.error('Error setting up audio monitoring:', error);
      }
    }

    // Replay recorded video
    function replayVideo() {
      if (videoPreview.src) {
        videoPreview.currentTime = 0;
        videoPreview.play();
      }
    }

    // Reshoot video
    function reshootVideo() {
      // Reset recording state
      recordedChunks = [];
      recordedVideoBlob = null;
      
      // Hide post-recording controls in dock
      hidePostRecordingControls();
      
      // Show start recording button
      startRecording.classList.remove('hidden');
      
      // Reset video preview to show camera feed
      if (stream) {
        videoPreview.srcObject = stream;
        videoPreview.muted = true;
        videoPreview.classList.remove('hidden');
        document.getElementById('videoPlaceholder').classList.add('hidden');
      } else {
        // If no stream, show placeholder
        videoPreview.classList.add('hidden');
        document.getElementById('videoPlaceholder').classList.remove('hidden');
      }
      
      // Stop audio monitoring
      if (audioContext) {
        audioContext.close();
        audioContext = null;
      }
      if (animationFrame) {
        cancelAnimationFrame(animationFrame);
      }
      document.getElementById('audioLevelIndicator').classList.add('hidden');
    }

    // Submit final video
    async function submitFinalVideo() {
      if (!recordedVideoBlob) {
        Swal.fire({
          icon: 'error',
          title: 'No Video',
          text: 'No recorded video found. Please record a video first.',
          confirmButtonColor: '#f1d85b',
          confirmButtonText: 'OK'
        });
        return;
      }

      const formData = new FormData();
      formData.append('video', recordedVideoBlob, 'followup-video.webm');
      formData.append('followupId', followupId);

      // Hide dock controls and show upload progress
      hidePostRecordingControls();
      uploadProgressDock.classList.remove('hidden');
      
      // Simulate upload progress
      simulateUploadProgress();

      try {
        const response = await fetch('/api/follow-up-queries/submit-video', {
          method: 'POST',
          body: formData,
          credentials: 'include'
        });

        if (!response.ok) {
          throw new Error('Failed to submit video');
        }

        // Hide upload progress and show processing loader
        uploadProgressDock.classList.add('hidden');
        processingLoaderDock.classList.remove('hidden');

        const data = await response.json();
        
        // Check if the response indicates success
        if (data.success && data.message) {
          // Hide processing loader and show completion message
          processingLoaderDock.classList.add('hidden');
          completionMessage.classList.remove('hidden');
        } else {
          // Handle unexpected response format
          throw new Error(data.error || 'Unexpected response format');
        }
        
      } catch (error) {
        console.error('Error submitting video:', error);
        
        // Determine error message based on the error
        let errorTitle = 'Upload Failed';
        let errorText = 'Failed to submit video. Please try again.';
        
        if (error.message.includes('parse Gemini response')) {
          errorTitle = 'Processing Failed';
          errorText = 'The video was uploaded but failed to process with AI. Please try again.';
        } else if (error.message.includes('Failed to submit video')) {
          errorTitle = 'Upload Failed';
          errorText = 'Failed to upload video to server. Please check your connection and try again.';
        }
        
        Swal.fire({
          icon: 'error',
          title: errorTitle,
          text: errorText,
          confirmButtonColor: '#f1d85b',
          confirmButtonText: 'OK'
        });
        
        uploadProgressDock.classList.add('hidden');
        processingLoaderDock.classList.add('hidden');
        showPostRecordingControls();
      }
    }

    // Submit video (legacy function for backward compatibility)
    async function submitVideoToServer() {
      return submitFinalVideo();
    }

    // Close welcome popup
    function closeWelcomePopup() {
      const popup = document.getElementById('welcomePopup');
      popup.classList.add('hidden');
    }

    // Close tab
    function closeTab() {
      // Try multiple methods to close the tab
      try {
        // Method 1: Standard window.close()
        window.close();
        
        // Method 2: Try to close via history
        if (window.history.length > 1) {
          window.history.back();
        }
        
        // Method 3: Try to navigate away
        window.location.href = 'about:blank';
        
        // If none of the above work, show instructions after a short delay
        setTimeout(() => {
          // Check if we're still on the same page
          if (window.location.href.includes('video.html')) {
            showCloseInstructions();
          }
        }, 200);
        
      } catch (error) {
        console.log('Auto-close failed, showing manual instructions');
        showCloseInstructions();
      }
    }

    // Show close instructions
    function showCloseInstructions() {
      Swal.fire({
        icon: 'info',
        title: 'How to Close This Tab',
        html: `
          <div class="text-left space-y-3">
            <p class="text-gray-700">You can close this tab using any of these methods:</p>
            <div class="space-y-2">
              <div class="flex items-center gap-2">
                <span class="bg-gray-200 px-2 py-1 rounded text-sm font-mono">Ctrl + W</span>
                <span class="text-sm text-gray-600">(Windows/Linux)</span>
              </div>
              <div class="flex items-center gap-2">
                <span class="bg-gray-200 px-2 py-1 rounded text-sm font-mono">Cmd + W</span>
                <span class="text-sm text-gray-600">(Mac)</span>
              </div>
              <div class="flex items-center gap-2">
                <span class="bg-gray-200 px-2 py-1 rounded text-sm font-mono">Click the X</span>
                <span class="text-sm text-gray-600">(On the tab)</span>
              </div>
            </div>
            <p class="text-sm text-gray-600 mt-3">Your video has been successfully submitted and processed!</p>
          </div>
        `,
        confirmButtonColor: '#f1d85b',
        confirmButtonText: 'Got it!',
        allowOutsideClick: false,
        allowEscapeKey: false
      });
    }

    // Event listeners
    startRecording.addEventListener('click', startRecordingVideo);
    stopRecording.addEventListener('click', stopRecordingVideo);
    
    // Dock controls event listeners
    document.getElementById('replayVideo').addEventListener('click', replayVideo);
    document.getElementById('reshootVideo').addEventListener('click', reshootVideo);
    document.getElementById('submitFinalVideo').addEventListener('click', submitFinalVideo);

    // Initialize when page loads
    document.addEventListener('DOMContentLoaded', initialize);
  </script>
</body>
</html>
